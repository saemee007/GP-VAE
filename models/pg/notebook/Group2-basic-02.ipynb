{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aSqRpBckAzM"
      },
      "source": [
        "# **Demo**\n",
        "\n",
        "### **1. Set environment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDNESmCoewLk",
        "outputId": "11c60256-87cb-4974-dbf4-3c89454c9237"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'GP-VAE'...\n",
            "remote: Enumerating objects: 49, done.\u001b[K\n",
            "remote: Counting objects: 100% (49/49), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 49 (delta 13), reused 42 (delta 9), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (49/49), done.\n"
          ]
        }
      ],
      "source": [
        "## own code\n",
        "!git clone https://github.com/saemee007/GP-VAE.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJxeFBI1iJTA",
        "outputId": "8182a73d-68f7-42e5-c26f-9dccbf461079"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboard==1.14\n",
            "  Downloading tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 7.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard==1.14) (1.15.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.8/dist-packages (from tensorboard==1.14) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard==1.14) (1.21.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard==1.14) (1.3.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard==1.14) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard==1.14) (3.4.1)\n",
            "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard==1.14) (1.50.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard==1.14) (3.19.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard==1.14) (0.38.4)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard==1.14) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard==1.14) (3.10.0)\n",
            "Installing collected packages: tensorboard\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.9.2 requires tensorboard<2.10,>=2.9, but you have tensorboard 1.14.0 which is incompatible.\u001b[0m\n",
            "Successfully installed tensorboard-1.14.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.4.0\n",
            "  Downloading torchtext-0.4.0-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 171 kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchtext==0.4.0) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchtext==0.4.0) (1.21.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from torchtext==0.4.0) (1.12.1+cu113)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torchtext==0.4.0) (4.64.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from torchtext==0.4.0) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.4.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.4.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.4.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.4.0) (2022.9.24)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->torchtext==0.4.0) (4.1.1)\n",
            "Installing collected packages: torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.13.1\n",
            "    Uninstalling torchtext-0.13.1:\n",
            "      Successfully uninstalled torchtext-0.13.1\n",
            "Successfully installed torchtext-0.4.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.14.1\n",
            "  Downloading transformers-4.14.1-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 15.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.14.1) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==4.14.1) (4.64.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 60.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.14.1) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 67.5 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 75.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.14.1) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.14.1) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.14.1) (3.8.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.14.1) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.14.1) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers==4.14.1) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.14.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.14.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.14.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.14.1) (2022.9.24)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.14.1) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.14.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.14.1) (1.2.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=ad782c0694f1dde76a9916050ab938753ff25b9c3434d29c893479410e79d873\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 sacremoses-0.0.53 tokenizers-0.10.3 transformers-4.14.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 15.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n"
          ]
        }
      ],
      "source": [
        "## own code\n",
        "!pip install tensorboard==1.14\n",
        "# !pip install tensorflow==1.14\n",
        "!pip install torchtext==0.4.0 \n",
        "!pip install transformers==4.14.1\n",
        "!pip install sentencepiece\n",
        "# !pip install https://download.pytorch.org/whl/cu101/torch-1.5.0%2Bcu101-cp37-cp37m-linux_x86_64.whl\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pBV0qcp-iac2"
      },
      "outputs": [],
      "source": [
        "## own code\n",
        "import sys\n",
        "\n",
        "sys.path.append('GP-VAE/models/pg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxQiNtCrkNrd"
      },
      "source": [
        "## **2.Set hyper-parameter**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AUQJJeVCkM7T"
      },
      "outputs": [],
      "source": [
        "## own code\n",
        "from easydict import EasyDict as edict\n",
        "\n",
        "args = edict({'task': 'train',\n",
        "             'data_file': 'GP-VAE/data/twitter_url_demo',\n",
        "             'model_type': 'gp_full',\n",
        "             'kernel_v': 65.0,\n",
        "             'kernel_r': 0.0001,\n",
        "             'epochs':1,\n",
        "             'batch_size': 64,\n",
        "             'optim': 2,\n",
        "             'lr': 0.001,\n",
        "             'grad_clip': 5.0,\n",
        "             'val_step': 1,\n",
        "             'print_step': 100,\n",
        "              'kw': 0.,\n",
        "              'x0': 25000,\n",
        "              'embed_size': 300,\n",
        "              'hidden_size': 512,\n",
        "              'latent_size': 256,\n",
        "              'word_dropout': 0,\n",
        "              'embed_dropout': 0.5,\n",
        "              'components': 10,\n",
        "              'kld_sampled':0,\n",
        "              'vocab_size': 20000,\n",
        "              'max_len': 30,\n",
        "              'using_cuda': True,\n",
        "              'sample_num': 10,\n",
        "              'beam_size': 10,\n",
        "              'model_file': None,\n",
        "              'topn':10,\n",
        "              'std':1.,\n",
        "              'decode_from': 'sample',\n",
        "              'seed': 123\n",
        "             })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XA7Phnl5kXSm"
      },
      "source": [
        "## **3. Create DataLoader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "L_3To-0PkZfv",
        "outputId": "93f8d150-ae7d-4bac-9d9c-e8d52be7359b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ce5cfdcc-3863-4854-9976-07bd6efb111d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ABC News staged crime-scene shot with police t...</td>\n",
              "      <td>More reason why the media can't always be trus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Pentagon says China will return a U.S. Nav...</td>\n",
              "      <td>China to return seized Navy drone AGAIN PE TRU...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Myanmar seeking ethnic cleansing of Muslim Roh...</td>\n",
              "      <td>The BBC app is worth downloading RIGHT NOW . M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Dylann Roof , the white supremacist who shot 9...</td>\n",
              "      <td>White supremacist terrorist Roof found guilty .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>President-elect @realDonaldTrump knocks border...</td>\n",
              "      <td>Trump blasts ' dishonest media , ' insists Mex...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce5cfdcc-3863-4854-9976-07bd6efb111d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ce5cfdcc-3863-4854-9976-07bd6efb111d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ce5cfdcc-3863-4854-9976-07bd6efb111d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                   0  \\\n",
              "0  ABC News staged crime-scene shot with police t...   \n",
              "1  The Pentagon says China will return a U.S. Nav...   \n",
              "2  Myanmar seeking ethnic cleansing of Muslim Roh...   \n",
              "3  Dylann Roof , the white supremacist who shot 9...   \n",
              "4  President-elect @realDonaldTrump knocks border...   \n",
              "\n",
              "                                                   1  \n",
              "0  More reason why the media can't always be trus...  \n",
              "1  China to return seized Navy drone AGAIN PE TRU...  \n",
              "2  The BBC app is worth downloading RIGHT NOW . M...  \n",
              "3    White supremacist terrorist Roof found guilty .  \n",
              "4  Trump blasts ' dishonest media , ' insists Mex...  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## own code\n",
        "import pandas as pd\n",
        "\n",
        "# Show raw data\n",
        "pd.read_csv(f'{args.data_file}/trn.tsv', sep='\\t', header=None).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5qLujVOkZ2L",
        "outputId": "69d5200b-6ae2-4540-8f0d-5201aadb3b4a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.8/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.8/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.8/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.8/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.8/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            ".vector_cache/glove.6B.zip: 862MB [02:44, 5.23MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:12<00:00, 31432.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TRAIN]:300 (dataset:19200)\t[VAL]:16 (dataset:1000)\t[TEST]:47 (dataset:3000)\n",
            "[vocab]:19062\n"
          ]
        }
      ],
      "source": [
        "## refactoring the auther's code\n",
        "import os\n",
        "import spacy\n",
        "from torchtext.data import Field, TabularDataset, BucketIterator\n",
        "\n",
        "spacy_en = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Tokenize English sentence\n",
        "def tokenize_fn(text):\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "# Define field\n",
        "TXT = Field(tokenize=tokenize_fn, init_token='<sos>', eos_token='<eos>', lower=True)\n",
        "\n",
        "# Source and target both are text\n",
        "fields = [(\"src\", TXT), (\"trg\", TXT)]\n",
        "\n",
        "# Create a Dataset instance \n",
        "trn_data = TabularDataset(os.path.join(args.data_file,'trn'+\".tsv\"), format=\"TSV\", fields=fields, skip_header=False)\n",
        "val_data = TabularDataset(os.path.join(args.data_file,'val'+\".tsv\"), format=\"TSV\", fields=fields, skip_header=False)\n",
        "tst_data = TabularDataset(os.path.join(args.data_file,'tst'+\".tsv\"), format=\"TSV\", fields=fields, skip_header=False)\n",
        "\n",
        "# Build vocab using training data\n",
        "TXT.build_vocab(trn_data, min_freq=1, vectors=\"glove.6B.100d\") # max_size=15000\n",
        "\n",
        "# Create iterator\n",
        "train_iter, val_iter, test_iter = BucketIterator.splits((trn_data, val_data, tst_data), \n",
        "                                                        batch_size=args.batch_size, \n",
        "                                                        sort_key=lambda x: len(x.src),\n",
        "                                                        sort=True,\n",
        "                                                        shuffle=False,\n",
        "                                                        repeat=False)\n",
        "txtfield = TXT\n",
        "\n",
        "print(\"[TRAIN]:%d (dataset:%d)\\t[VAL]:%d (dataset:%d)\\t[TEST]:%d (dataset:%d)\"\n",
        "      % (len(train_iter), len(train_iter.dataset),\n",
        "         len(val_iter), len(val_iter.dataset),\n",
        "         len(test_iter), len(test_iter.dataset)))\n",
        "print(\"[vocab]:%d\" % (len(txtfield.vocab)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YVNFC1UBkuMR",
        "outputId": "de85788e-8f44-4920-b3ff-129c99f98e2e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'abc news staged crime - scene shot with police tape , photograph shows'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## own code\n",
        "# Example of source text\n",
        "\n",
        "' '.join(list(iter(trn_data.src))[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "14_y5xkok-AH",
        "outputId": "e3421a8a-ae7f-4d20-d72c-a5820f25c427"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"more reason why the media ca n't always be trusted abc news staged crime - scene shot , photo shows\""
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## own code\n",
        "# Example of target text\n",
        "\n",
        "' '.join(list(iter(trn_data.trg))[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1381T6yk_oY"
      },
      "source": [
        "## **4. Initialize the model**\n",
        "\n",
        "Create a model instance using a **GP FULL** class.  \n",
        "GP FULL is a point-generator architecture using Gaussian priors. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1ab0k3Uvk-9Q"
      },
      "outputs": [],
      "source": [
        "## refactoring the author's code\n",
        "from model import GP_Full\n",
        "\n",
        "\n",
        "# Create model instance\n",
        "model = GP_Full(args, txtfield)\n",
        "model = model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ib7XtBLkla9u",
        "outputId": "34c7b4a9-8414-4999-dccc-b1432b47d3f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GP_Full(\n",
              "  (embedding): Embedding(20000, 300)\n",
              "  (bi_lstm): LSTM(300, 512, batch_first=True, bidirectional=True)\n",
              "  (hidden2latent): Linear(in_features=1024, out_features=256, bias=True)\n",
              "  (latent2hidden): Linear(in_features=256, out_features=1024, bias=True)\n",
              "  (reduce_h): Linear(in_features=1024, out_features=512, bias=True)\n",
              "  (reduce_c): Linear(in_features=1024, out_features=512, bias=True)\n",
              "  (W_h): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "  (W_c): Linear(in_features=1, out_features=1024, bias=False)\n",
              "  (decode_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "  (v): Linear(in_features=1024, out_features=1, bias=False)\n",
              "  (x_context): Linear(in_features=1324, out_features=300, bias=True)\n",
              "  (uni_lstm): LSTM(300, 512, batch_first=True)\n",
              "  (p_gen_linear): Linear(in_features=2348, out_features=1, bias=True)\n",
              "  (out1): Linear(in_features=1536, out_features=512, bias=True)\n",
              "  (out2): Linear(in_features=512, out_features=20000, bias=True)\n",
              "  (mean): Linear(in_features=1024, out_features=256, bias=True)\n",
              "  (logvar): Linear(in_features=1024, out_features=256, bias=True)\n",
              "  (enc_latent): Linear(in_features=1024, out_features=256, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBHnh_PTlddL"
      },
      "source": [
        "## **5. Set optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jE3Tz_9nlfCQ"
      },
      "outputs": [],
      "source": [
        "## refactoring the author's code\n",
        "from torch import optim\n",
        "\n",
        "\n",
        "# Create optimizer instance\n",
        "params = model.parameters()\n",
        "optimizer = optim.Adam(params, lr=args.lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rd2YWI-AlhKf"
      },
      "source": [
        "## **6. Train**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIB5667zlf-S",
        "outputId": "8da3f81f-46ce-4ed8-8839-3e9b1ec93e18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*** Training with validation ... ***\n",
            "[!] saving model...\n"
          ]
        }
      ],
      "source": [
        "## refactoring the author's code\n",
        "import logging\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "import absl.logging\n",
        "from training import evaluate\n",
        "logging.root.removeHandler(absl.logging._absl_handler)\n",
        "absl.logging._warn_preinit_stderr = False\n",
        "\n",
        "import torch\n",
        "from torch import autograd\n",
        "from torch.nn.utils import clip_grad_norm_ as clip_grad_norm\n",
        "from utils import kl_anneal_weight\n",
        "\n",
        "print(\"*** Training with validation ... ***\")\n",
        "\n",
        "# Check current time\n",
        "curr_time = datetime.datetime.now()\n",
        "time_stamp = \"{}-{}-{}-{}-{}-{}\".format(curr_time.year, curr_time.month, curr_time.day,\n",
        "                                            curr_time.hour, curr_time.minute, curr_time.second)\n",
        "\n",
        "# Set output directory name\n",
        "data_file = args.data_file.split('/')[-1]\n",
        "wpath = \"GP-VAE/models/pg/notebook/logs_\"+data_file\n",
        "fprefix = '{}_k{}_h{}_c{}_r{}_v{}_t{}'.format(args.model_type, args.latent_size, \n",
        "                                              args.hidden_size, args.components, \n",
        "                                              args.kernel_r, args.kernel_v,\n",
        "                                              time_stamp)\n",
        "if not os.path.isdir(wpath):\n",
        "    os.makedirs(wpath)\n",
        "flog = os.path.join(wpath, fprefix+\".log\")\n",
        "logging.basicConfig(format='%(asctime)s %(message)s',\n",
        "                    datefmt='%Y-%m-%d %I:%M:%S %p',\n",
        "                    handlers=[\n",
        "                        logging.FileHandler(flog), # to file\n",
        "                        logging.StreamHandler() # to stdout\n",
        "                    ],\n",
        "                    level=logging.INFO)\n",
        "logging.info(\"File name prefix: {}\".format(fprefix))\n",
        "logging.info(args)\n",
        "logging.info(model)\n",
        "\n",
        "# -----------------------------\n",
        "# Create tensorboard logs\n",
        "eval_log = 'GP-VAE/models/pg/notebook/tensorboard_logs_'+data_file+'/' + fprefix\n",
        "if not os.path.exists(eval_log):\n",
        "    os.makedirs(eval_log)\n",
        "# summary_writer = tf.summary.FileWriter(eval_log) \n",
        "\n",
        "# -----------------------------\n",
        "# Start training\n",
        "global_step = 0\n",
        "early_stop = 0\n",
        "best_val_loss = 1000\n",
        "for e in range(1, args.epochs+1):\n",
        "    for b, batch in enumerate(train_iter):\n",
        "        \n",
        "        # Set model to training mode\n",
        "        model.train()\n",
        "        \n",
        "        # Initialize gradient to zeros\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Predict and calculate losses\n",
        "        nll, kld = model(batch)\n",
        "        kl_weight = kl_anneal_weight(global_step, args)\n",
        "\n",
        "        loss = nll + kl_weight * kld\n",
        "        \n",
        "        # Backpropagate\n",
        "        loss.backward()\n",
        "        \n",
        "        # Clip gradient\n",
        "        clip_grad_norm(model.parameters(), args.grad_clip) \n",
        "        \n",
        "        # Update weight\n",
        "        optimizer.step()\n",
        "        global_step += 1\n",
        "        \n",
        "        # Print result\n",
        "        if global_step % args.print_step == 0:\n",
        "            logging.info(\"[Epoch: %d] [Batch: %d/%d] [NLL: %.4f] [KLD: %.4f]\" % \n",
        "                        (e, b+1, len(train_iter), nll, kld))\n",
        "            \n",
        "            # Add nll, kld into tensorboard\n",
        "            # train_nll = tf.Summary()\n",
        "            # train_nll.value.add(tag='train_nll', simple_value=nll)\n",
        "            # summary_writer.add_summary(train_nll, global_step=global_step)\n",
        "            # summary_writer.flush()\n",
        "            # train_kld = tf.Summary()\n",
        "            # train_kld.value.add(tag='train_kld', simple_value=kld)\n",
        "            # summary_writer.add_summary(train_kld, global_step=global_step)\n",
        "            # summary_writer.flush()\n",
        "            # kld_weight = tf.Summary()\n",
        "            # kld_weight.value.add(tag='kld_weight', simple_value=kl_weight)\n",
        "            # summary_writer.add_summary(kld_weight, global_step=global_step)\n",
        "            # summary_writer.flush()\n",
        "\n",
        "    # Start validation\n",
        "    if e % args.val_step == 0:\n",
        "\n",
        "        val_nll, val_kld = evaluate(model, val_iter, txtfield, args)\n",
        "        logging.info(\"Val => [Current NLL: %5.4f] [Current KLD: %5.4f] [Best Loss: %5.4f]\" \n",
        "                     % (val_nll, val_kld, best_val_loss))\n",
        "\n",
        "        val_loss = val_nll + val_kld\n",
        "        early_stop += 1\n",
        "        \n",
        "        # Update the best model\n",
        "        if val_loss < best_val_loss:\n",
        "            print(\"[!] saving model...\")\n",
        "            torch.save(model.state_dict(), os.path.join(wpath, fprefix+\".pt\"))\n",
        "            best_val_loss = val_loss\n",
        "            early_stop = 0\n",
        "            \n",
        "        # Add val_loss into tensorboard\n",
        "        # loss_sum = tf.Summary()\n",
        "        # loss_sum.value.add(tag='val_loss', simple_value=val_loss)\n",
        "        # summary_writer.add_summary(loss_sum, global_step=int(e/args.val_step))\n",
        "        # summary_writer.flush()\n",
        "\n",
        "    # Stop training if no improvement\n",
        "    if early_stop > 10: \n",
        "        print('No improvement after 10 epochs, stop training ...')\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_hns4Wplu9S"
      },
      "source": [
        "## **7.Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgRHJ9hjlkGT",
        "outputId": "57547d8c-8e6b-4f45-b9b4-385d31824f64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*** Testing ... ***\n",
            "[TEST] NLL: 5.8678 KLD: 0.9838 PPLx: 945.3456\n"
          ]
        }
      ],
      "source": [
        "## refactoring the author's code\n",
        "from math import exp\n",
        "\n",
        "print(\"*** Testing ... ***\")\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "total_nll, total_kld, total_batch = 0., 0., 0.\n",
        "for b, batch in enumerate(test_iter):\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        # Predict and calculate losses\n",
        "        nll, kld = model(batch, test=True)\n",
        "        total_nll += nll.item()\n",
        "        total_kld += kld.item()\n",
        "        total_batch += 1\n",
        "\n",
        "avg_nll = total_nll / total_batch\n",
        "avg_kld = total_kld / total_batch\n",
        "\n",
        "test_nll = avg_nll\n",
        "test_kld = avg_kld\n",
        "\n",
        "print(\"[TEST] NLL: %5.4f KLD: %5.4f PPLx: %5.4f\" % (test_nll, test_kld, exp(test_nll+test_kld)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xMoaY0Xl2R2"
      },
      "source": [
        "## **8. Load the model**\n",
        "\n",
        "To test **pre-trained model** (trained by Saemee and Karl),  \n",
        "please download [model weight](https://drive.google.com/uc?id=1IxOHH51gnBqPAoNkA94QWHkqettgV2hW&amp;confirm=t&amp;uuid=3d3f8aef-116f-4b3f-b508-1384cfd84ec0&amp;at=AHV7M3f4dM7D8lDZJkKH0N_70sUA:1670236230821), and move it to `GP-VAE/models/pg/notebook/logs_twitter_url_tot/best_model.pt`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-Kn5hY9l6CN",
        "outputId": "7f7ca52d-32b9-41ad-f1fe-9a519921a741"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading the pretrained model from: GP-VAE/models/pg/notebook/logs_twitter_url_tot/best_model.pt\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## refactoring the author's code\n",
        "args.model_file = 'GP-VAE/models/pg/notebook/logs_twitter_url_tot/best_model.pt'\n",
        "\n",
        "print(\"Loading the pretrained model from: {}\".format(args.model_file))\n",
        "\n",
        "# Load the best model weights\n",
        "model.load_state_dict(torch.load(args.model_file, map_location='cuda:0'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mREUoCBrT-C",
        "outputId": "e7f8b04a-db88-4d60-f473-a8ac69bcafd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*** Testing ... ***\n",
            "[TEST] NLL: 5.1754 KLD: 0.0425 PPLx: 184.5394\n"
          ]
        }
      ],
      "source": [
        "## refactoring the author's code\n",
        "from math import exp\n",
        "\n",
        "print(\"*** Testing ... ***\")\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "total_nll, total_kld, total_batch = 0., 0., 0.\n",
        "for b, batch in enumerate(test_iter):\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        # Predict and calculate losses\n",
        "        nll, kld = model(batch, test=True)\n",
        "        total_nll += nll.item()\n",
        "        total_kld += kld.item()\n",
        "        total_batch += 1\n",
        "\n",
        "avg_nll = total_nll / total_batch\n",
        "avg_kld = total_kld / total_batch\n",
        "\n",
        "test_nll = avg_nll\n",
        "test_kld = avg_kld\n",
        "\n",
        "print(\"[TEST] NLL: %5.4f KLD: %5.4f PPLx: %5.4f\" % (test_nll, test_kld, exp(test_nll+test_kld)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_swWtevUrVNH"
      },
      "source": [
        "## **9. Application**\n",
        "Paraphrase Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3nZ-VrKomK9",
        "outputId": "0d584891-c32c-4b1b-dcd6-1cf203ac8adf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "growing divide between red and blue america\n",
            "growing divide between red and blue america\n",
            "the growing divide between red and blue america\n",
            "growing divide between red and blue america\n",
            "growing divide between red and blue america\n",
            "the growing divide between red and blue america\n",
            "growing divide between red its first an blue america\n",
            "growing divide between red , blue america\n",
            "growing divide between red and blue america .\n",
            "growing again and blue america\n",
            "Input words: the growing divide between red and blue america\n",
            "Ref words: education , wealth , new economy , and diversity divide u.s. divide between red and blue america ?\n",
            "Pred words: growing divide between red and blue america\n",
            "Percent of unique sentences: 0.6\n",
            "\n",
            "could your own immune system kill cancer ?\n",
            "could your own immune system kill cancer ?\n",
            "the could your own immune system kill cancer ?\n",
            "could your own immune system kill cancer ?\n",
            "could your own immune system kill cancer ?\n",
            "could president own immune system kill cancer ?\n",
            "could not own immune system kill cancer ?\n",
            "could your own immune system kill cancer ?\n",
            "the could your own immune system kill cancer ?\n",
            "could your own immune system kill cancer ?\n",
            "the could your own immune system kill cancer ?\n",
            "his own immune system kill cancer ?\n",
            "Input words: could your own immune system kill cancer ?\n",
            "Ref words: can our own immune system kill cancer cells ?\n",
            "Pred words: could your own immune system kill cancer ?\n",
            "Percent of unique sentences: 0.4166666666666667\n",
            "\n",
            "hillary clinton wins dixville notch 's midnight vote\n",
            "hillary clinton wins dixville notch 's midnight vote\n",
            "hillary clinton wins dixville notch 's midnight vote with times all\n",
            "clinton wins dixville notch 's midnight vote\n",
            "hillary clinton wins dixville notch 's midnight vote\n",
            "hillary clinton wins dixville notch 's midnight vote\n",
            "hillary clinton wins dixville notch 's midnight vote\n",
            "hillary clinton wins dixville notch 's midnight vote\n",
            "hillary clinton wins notch 's midnight vote\n",
            "hillary clinton wins dixville notch 's midnight vote\n",
            "Input words: hillary clinton wins dixville notch 's midnight vote\n",
            "Ref words: the first votes in the country , and hillary clinton wins against the # <unk> !\n",
            "Pred words: hillary clinton wins dixville notch 's midnight vote\n",
            "Percent of unique sentences: 0.4\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.8/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "donald trump finds an improbable ally in wikileaks\n",
            "donald trump finds an improbable ally ally in\n",
            "the finds an improbable ally in wikileaks\n",
            "donald trump finds an improbable ally in\n",
            "donald playing improbable ally in wikileaks\n",
            "donald trump finds , improbable ally in wikileaks\n",
            "trump finds an improbable ally in wikileaks\n",
            "donald in wikileaks\n",
            "in wikileaks\n",
            "improbable ally in wikileaks\n",
            "Input words: donald trump finds an improbable ally in wikileaks\n",
            "Ref words: donald trump finds improbable ally in wikileaks u.s.\n",
            "Pred words: donald trump finds an improbable ally in wikileaks\n",
            "Percent of unique sentences: 1.0\n",
            "\n",
            "how the brown rat conquered new york city\n",
            "how the brown rat conquered new york city\n",
            "how the brown rat conquered new york city .\n",
            "how brown rat conquered new york city\n",
            "how the # brown rat conquered new york city\n",
            "was the brown rat conquered new york city\n",
            "brown rat conquered new york city\n",
            "how the brown conquered new york city\n",
            "the brown rat conquered new york city\n",
            "brown conquered new york city\n",
            "Input words: how the brown rat conquered new york city\n",
            "Ref words: how the mean , mysterious brown rat took over cities\n",
            "Pred words: how the brown rat conquered new york city\n",
            "Percent of unique sentences: 0.9\n",
            "\n",
            "facebook accused of removing breast cancer awareness video\n",
            "facebook accused of removing breast cancer awareness\n",
            "facebook accused of removing breast cancer awareness video\n",
            "facebook accused of removing breast cancer awareness .\n",
            "facebook accused of removing breast cancer awareness video\n",
            "facebook accused of removing breast cancer awareness video .\n",
            "facebook accused of removing breast cancer awareness\n",
            "facebook accused of removing breast cancer awareness video\n",
            "facebook accused of removing breast cancer awareness video\n",
            "facebook accused of removing breast cancer awareness video\n",
            "facebook accused of removing breast cancer awareness video\n",
            "Input words: facebook accused of removing breast cancer awareness video\n",
            "Ref words: linux and open source , facebook accused of removing breast cancer <unk>\n",
            "Pred words: facebook accused of removing breast cancer awareness video\n",
            "Percent of unique sentences: 0.36363636363636365\n",
            "\n",
            "gretchen carlson on her fight against sexual harassment\n",
            "gretchen on her fight against sexual harassment\n",
            "gretchen carlson a her fight against sexual harassment\n",
            "gretchen carlson ' her fight against sexual harassment\n",
            "her fight against sexual harassment\n",
            "gretchen carlson on her fight against sexual harassment\n",
            "gretchen carlson \" her fight against sexual harassment\n",
            "gretchen carlson on her fight against sexual harassment .\n",
            "gretchen carlson , her fight against sexual harassment\n",
            "fight against sexual harassment\n",
            "gretchen carlson at fight against sexual harassment\n",
            "Input words: gretchen carlson on her fight against sexual harassment\n",
            "Ref words: a must read by <unk> gretchen carlson my fight against sexual harassment\n",
            "Pred words: gretchen carlson on her fight against sexual harassment\n",
            "Percent of unique sentences: 0.9090909090909091\n",
            "\n",
            "all of your election day <unk> , answered\n",
            "all of your election day <unk> , answered\n",
            "all of your election day <unk> , answered\n",
            "the all of your election day <unk> , answered\n",
            "all of your election day <unk> , answered .\n",
            "all of your election day <unk> , answered\n",
            "all of your election day <unk> , answered\n",
            "your election day <unk> , answered\n",
            "trump your election day <unk> , answered\n",
            "the your election day <unk> , answered\n",
            "all of your election day <unk>\n",
            "day <unk> , answered\n",
            "Input words: all of your election day <unk> , answered\n",
            "Ref words: why elections are on work days , and other handy election facts\n",
            "Pred words: all of your election day <unk> , answered\n",
            "Percent of unique sentences: 0.6666666666666666\n",
            "\n",
            "sorry apple , but everyone thinks microsoft won\n",
            "sorry apple , but everyone thinks microsoft won\n",
            "sorry apple , but at but everyone thinks microsoft won\n",
            "sorry apple , but everyone thinks microsoft won .\n",
            "sorry # apple , but everyone thinks microsoft won\n",
            "sorry apple , but everyone thinks microsoft won\n",
            "sorry apple , but everyone thinks microsoft won\n",
            "sorry apple , but everyone thinks microsoft won\n",
            "apple , but everyone thinks microsoft won\n",
            "but everyone thinks microsoft won\n",
            "Input words: sorry apple , but everyone thinks microsoft won\n",
            "Ref words: sorry , apple , microsoft wins this round\n",
            "Pred words: sorry apple , but everyone thinks microsoft won\n",
            "Percent of unique sentences: 0.6\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "watch our new series bitcoin and the blockchain\n",
            "watch our new series bitcoin and the blockchain\n",
            "watch our new series bitcoin and the blockchain\n",
            "watch our new series bitcoin and the blockchain\n",
            "watch our new series bitcoin and the blockchain .\n",
            "watch our new series bitcoin its first an the blockchain\n",
            "watch our new series bitcoin its first an blockchain\n",
            "watch our new series bitcoin , the blockchain\n",
            "watch our new series bitcoin and blockchain\n",
            "watch our new series bitcoin , blockchain\n",
            "Input words: watch our new series bitcoin and the blockchain\n",
            "Ref words: retweeted <unk> <unk> watch our new series bitcoin and the .\n",
            "Pred words: watch our new series bitcoin and the blockchain\n",
            "Percent of unique sentences: 0.7\n",
            "\n",
            "trump takes aim at first lady michelle obama\n",
            "trump takes aim at first lady michelle obama\n",
            "trump takes aim at first lady michelle obama .\n",
            "trump takes aim at the lady michelle obama\n",
            "the takes aim at first lady michelle obama\n",
            "takes aim at first lady michelle obama\n",
            "trump takes aim at lady michelle obama\n",
            "aim at first lady michelle obama\n",
            "trump takes aim at first lady michelle\n",
            "lady michelle obama\n",
            "Input words: trump takes aim at first lady michelle obama\n",
            "Ref words: donald trump takes <unk> aim at first lady michelle obama .\n",
            "Pred words: trump takes aim at first lady michelle obama\n",
            "Percent of unique sentences: 0.9\n",
            "\n",
            "donald trump finds an improbable ally in wikileaks\n",
            "donald trump finds an improbable ally ally in\n",
            "the finds an improbable ally in wikileaks\n",
            "donald trump finds an improbable ally in\n",
            "donald playing improbable ally in wikileaks\n",
            "donald trump finds , improbable ally in wikileaks\n",
            "trump finds an improbable ally in wikileaks\n",
            "donald in wikileaks\n",
            "in wikileaks\n",
            "improbable ally in wikileaks\n",
            "Input words: donald trump finds an improbable ally in wikileaks\n",
            "Ref words: new york times most viewed stories donald trump finds improbable ally in wikileaks\n",
            "Pred words: donald trump finds an improbable ally in wikileaks\n",
            "Percent of unique sentences: 1.0\n",
            "\n",
            "how moscow uses interpol to pursue its enemies\n",
            "how moscow uses interpol to pursue its enemies\n",
            "how moscow uses interpol to pursue its first an enemies\n",
            "how moscow uses interpol to pursue its enemies\n",
            "moscow uses interpol to pursue its enemies\n",
            "how moscow uses interpol to pursue its enemies\n",
            "how moscow uses interpol to pursue its first an enemies\n",
            "how moscow uses interpol to pursue its enemies\n",
            "how moscow uses interpol to pursue its enemies\n",
            "how moscow uses interpol to pursue its enemies\n",
            "moscow uses interpol to pursue its enemies\n",
            "how moscow uses interpol to pursue its drug an enemies\n",
            "how moscow uses interpol to pursue enemies\n",
            "Input words: how moscow uses interpol to pursue its enemies\n",
            "Ref words: putin uses interpol to punish political enemies abroad , and interpol ca n't do anything about it .\n",
            "Pred words: how moscow uses interpol to pursue its enemies\n",
            "Percent of unique sentences: 0.38461538461538464\n",
            "\n",
            "google 's ai creates its first an own <unk> encryption\n",
            "google 's ai creates its first an google 's ai creates\n",
            "google 's ai creates , own <unk> encryption\n",
            "google 's ai creates its own <unk> encryption\n",
            "google 's ai creates its first an own <unk> encryption\n",
            "google 's ai creates its first an own <unk> encryption .\n",
            "google 's ai creates is own <unk> encryption\n",
            "google 's ai creates its first an own <unk>\n",
            "google 's ai creates its own <unk> encryption\n",
            "google 's ai creates its first an google 's ai\n",
            "google 's ai creates its first an own <unk>\n",
            "google 's ai creates its own <unk> encryption\n",
            "Input words: google 's ai creates its own <unk> encryption\n",
            "Ref words: another mega yacht marketing top story googles ai creates its own <unk> <unk>\n",
            "Pred words: google 's ai creates its first an own <unk> encryption\n",
            "Percent of unique sentences: 0.6666666666666666\n",
            "\n",
            "early turnout tilts toward democrats in swing states\n",
            "early turnout tilts toward democrats in swing states\n",
            "early turnout tilts toward democrats in swing states via radio\n",
            "early turnout tilts toward democrats in swing states .\n",
            "early turnout tilts toward democrats in swing states\n",
            "early turnout tilts toward democrats in swing states video\n",
            "early turnout tilts toward democrats in swing states\n",
            "early turnout tilts toward democrats in swing states\n",
            "early turnout tilts toward democrats in swing states\n",
            "early turnout tilts toward democrats toward democrats\n",
            "early turnout tilts toward democrats\n",
            "early turnout tilts toward democrats\n",
            "Input words: early turnout tilts toward democrats in swing states\n",
            "Ref words: turnout tilts toward democrats swing states bul shit lyin nytimes this y i don't <unk> buy ur <unk> paper trash\n",
            "Pred words: early turnout tilts toward democrats in swing states\n",
            "Percent of unique sentences: 0.5\n",
            "\n",
            "wisconsin projected by abc news for @realdonaldtrump .\n",
            "wisconsin projected by abc news for @realdonaldtrump . on government\n",
            "wisconsin projected by abc news for @realdonaldtrump . with times all\n",
            "wisconsin projected by abc news for @realdonaldtrump with times all\n",
            "wisconsin projected by abc news for @realdonaldtrump\n",
            "wisconsin projected by abc news for @realdonaldtrump with times all\n",
            "wisconsin projected by abc news for @realdonaldtrump . on government\n",
            "wisconsin projected by abc news @realdonaldtrump .\n",
            "projected by abc news for @realdonaldtrump .\n",
            "wisconsin projected by abc news .\n",
            "Input words: wisconsin projected by abc news for @realdonaldtrump .\n",
            "Ref words: massachusetts projected by abc news for @hillaryclinton .\n",
            "Pred words: wisconsin projected by abc news for @realdonaldtrump .\n",
            "Percent of unique sentences: 0.8\n",
            "\n",
            "walk of fame star destroyed , police investigate\n",
            "walk of fame star destroyed , police investigate\n",
            "walk of fame star destroyed with times all\n",
            "walk of fame star destroyed , police investigate\n",
            "walk of fame star destroyed with times all\n",
            "walk of fame star destroyed , police investigate\n",
            "walk of fame star destroyed is police investigate\n",
            "walk of fame star destroyed , police\n",
            "walk of fame star destroyed , and police investigate\n",
            "walk of fame star destroyed , security investigate\n",
            "walk of fame star destroyed and police investigate\n",
            "walk of fame star destroyed with times all\n",
            "walk of fame star destroyed , police investigate\n",
            "Input words: walk of fame star destroyed , police investigate\n",
            "Ref words: trumps walk of fame star has been destroyed , police are currently investigating the event .\n",
            "Pred words: walk of fame star destroyed , police investigate\n",
            "Percent of unique sentences: 0.5384615384615384\n",
            "\n",
            "wisconsin projected by abc news for @realdonaldtrump .\n",
            "wisconsin projected by abc news for @realdonaldtrump . on government\n",
            "wisconsin projected by abc news for @realdonaldtrump . with times all\n",
            "wisconsin projected by abc news for @realdonaldtrump with times all\n",
            "wisconsin projected by abc news for @realdonaldtrump\n",
            "wisconsin projected by abc news for @realdonaldtrump with times all\n",
            "wisconsin projected by abc news for @realdonaldtrump . on government\n",
            "wisconsin projected by abc news @realdonaldtrump .\n",
            "projected by abc news for @realdonaldtrump .\n",
            "wisconsin projected by abc news .\n",
            "Input words: wisconsin projected by abc news for @realdonaldtrump .\n",
            "Ref words: massachusetts projected by abc news for @hillaryclinton .\n",
            "Pred words: wisconsin projected by abc news for @realdonaldtrump .\n",
            "Percent of unique sentences: 0.8\n",
            "\n",
            "walk of fame star destroyed , police investigate\n",
            "walk of fame star destroyed , police investigate\n",
            "walk of fame star destroyed with times all\n",
            "walk of fame star destroyed , police investigate\n",
            "walk of fame star destroyed with times all\n",
            "walk of fame star destroyed , police investigate\n",
            "walk of fame star destroyed is police investigate\n",
            "walk of fame star destroyed , police\n",
            "walk of fame star destroyed , and police investigate\n",
            "walk of fame star destroyed , security investigate\n",
            "walk of fame star destroyed and police investigate\n",
            "walk of fame star destroyed with times all\n",
            "walk of fame star destroyed , police investigate\n",
            "Input words: walk of fame star destroyed , police investigate\n",
            "Ref words: walk of fame star destroyed with sledgehammer\n",
            "Pred words: walk of fame star destroyed , police investigate\n",
            "Percent of unique sentences: 0.5384615384615384\n",
            "\n",
            "twitter still might save vine by selling it\n",
            "twitter still might save vine by selling it the with times all\n",
            "twitter still might save vine by selling it on government\n",
            "twitter still might save vine by selling it by # enemies stunning\n",
            "twitter still might save vine by selling it with times all\n",
            "twitter still might save vine by selling it with times all\n",
            "twitter still might save vine by selling it on government\n",
            "twitter still might save vine by selling it the with times can\n",
            "still might save vine by selling it\n",
            "twitter still might save vine by selling it on government\n",
            "might save vine by selling it\n",
            "twitter still might save vine by selling it on government\n",
            "twitter still might save vine by selling\n",
            "save vine by selling it\n",
            "vine by selling it\n",
            "Input words: twitter still might save vine by selling it\n",
            "Ref words: apparently twitter might save vine by selling it\n",
            "Pred words: twitter still might save vine by selling it\n",
            "Percent of unique sentences: 0.7333333333333333\n",
            "\n",
            "career is over troubled waters\n",
            "chris christie 's career is over troubled waters\n",
            "chris christie 's career is over troubled waters\n",
            "christie 's career is over troubled waters\n",
            "career is over troubled waters\n",
            "career is over troubled waters\n",
            "christie 's career is over troubled waters\n",
            "career is over troubled waters\n",
            "career is over troubled waters\n",
            "career , over troubled waters\n",
            "career , troubled waters\n",
            "Input words: chris christie 's career is over troubled waters\n",
            "Ref words: chris christie 's career is over and so is trump 's .\n",
            "Pred words: career is over troubled waters\n",
            "Percent of unique sentences: 0.45454545454545453\n",
            "\n",
            "how artificial intelligence is changing online retail forever\n",
            "how artificial intelligence is changing online retail forever\n",
            "artificial intelligence is changing online retail forever\n",
            "how artificial intelligence is changing online retail forever .\n",
            "how artificial intelligence is changing online retail forever\n",
            "how artificial intelligence is changing online retail forever\n",
            "artificial intelligence is changing online retail forever\n",
            "how artificial intelligence artificial intelligence is changing online retail forever\n",
            "how artificial intelligence online retail forever\n",
            "how artificial intelligence artificial forever\n",
            "changing online retail forever\n",
            "artificial forever\n",
            "Input words: how artificial intelligence is changing online retail forever\n",
            "Ref words: report on how # ai is changing online retail\n",
            "Pred words: how artificial intelligence is changing online retail forever\n",
            "Percent of unique sentences: 0.6666666666666666\n",
            "\n",
            "wisconsin projected by abc news for @realdonaldtrump .\n",
            "wisconsin projected by abc news for @realdonaldtrump . on government\n",
            "wisconsin projected by abc news for @realdonaldtrump . with times all\n",
            "wisconsin projected by abc news for @realdonaldtrump with times all\n",
            "wisconsin projected by abc news for @realdonaldtrump\n",
            "wisconsin projected by abc news for @realdonaldtrump with times all\n",
            "wisconsin projected by abc news for @realdonaldtrump . on government\n",
            "wisconsin projected by abc news @realdonaldtrump .\n",
            "projected by abc news for @realdonaldtrump .\n",
            "wisconsin projected by abc news .\n",
            "Input words: wisconsin projected by abc news for @realdonaldtrump .\n",
            "Ref words: pennsylvania projected by abc news for @realdonaldtrump .\n",
            "Pred words: wisconsin projected by abc news for @realdonaldtrump .\n",
            "Percent of unique sentences: 0.8\n",
            "\n",
            "hollywood walk of fame star smashed with sledgehammer\n",
            "hollywood walk of fame star smashed with sledgehammer\n",
            "hollywood walk of fame star smashed with sledgehammer via radio\n",
            "hollywood walk of fame star smashed with sledgehammer\n",
            "hollywood walk of fame star smashed with sledgehammer .\n",
            "hollywood walk of fame star smashed with sledgehammer ambassador\n",
            "hollywood walk of fame star smashed with sledgehammer\n",
            "hollywood walk of fame star smashed with sledgehammer via twitter\n",
            "hollywood walk of star smashed with sledgehammer\n",
            "walk of fame star smashed with sledgehammer\n",
            "Input words: hollywood walk of fame star smashed with sledgehammer\n",
            "Ref words: all politicians should be smashed with <unk> . oh hollywood star ?\n",
            "Pred words: hollywood walk of fame star smashed with sledgehammer\n",
            "Percent of unique sentences: 0.7\n",
            "\n",
            "how artificial intelligence is changing online retail forever\n",
            "how artificial intelligence is changing online retail forever\n",
            "artificial intelligence is changing online retail forever\n",
            "how artificial intelligence is changing online retail forever .\n",
            "how artificial intelligence is changing online retail forever\n",
            "how artificial intelligence is changing online retail forever\n",
            "artificial intelligence is changing online retail forever\n",
            "how artificial intelligence artificial intelligence is changing online retail forever\n",
            "how artificial intelligence online retail forever\n",
            "how artificial intelligence artificial forever\n",
            "changing online retail forever\n",
            "artificial forever\n",
            "Input words: how artificial intelligence is changing online retail forever\n",
            "Ref words: top in how artificial intelligence is changing onli\n",
            "Pred words: how artificial intelligence is changing online retail forever\n",
            "Percent of unique sentences: 0.6666666666666666\n",
            "\n",
            "battle for mosul begins , iraqi pm says\n",
            "battle for mosul begins , iraqi pm says with times all\n",
            "battle for mosul begins , iraqi pm says via radio\n",
            "battle for mosul begins , iraqi pm says\n",
            "battle for mosul begins , iraqi pm says via radio\n",
            "battle for mosul begins , iraqi pm says .\n",
            "battle for mosul begins , iraqi pm says\n",
            "battle for mosul begins , iraqi pm says\n",
            "battle for mosul begins , iraqi pm says\n",
            "battle for mosul begins , iraqi pm\n",
            "battle for mosul begins , iraqi pm says\n",
            "Input words: battle for mosul begins , iraqi pm says\n",
            "Ref words: battle for # mosul , operation to retake # iraqi city from # daesh ' begins\n",
            "Pred words: battle for mosul begins , iraqi pm says\n",
            "Percent of unique sentences: 0.45454545454545453\n",
            "\n",
            "team trump is already filled with washington insiders\n",
            "team trump is already filled with washington insiders .\n",
            "team trump is already filled with washington insiders\n",
            "trump is already filled with washington insiders\n",
            "the is already filled with washington insiders\n",
            "already filled with washington insiders\n",
            "is already filled with washington insiders\n",
            "team trump is already filled with washington\n",
            "filled with washington insiders\n",
            "team trump with washington insiders\n",
            "with washington insiders\n",
            "Input words: team trump is already filled with washington insiders\n",
            "Ref words: so , more # <unk> instead of # draintheswamp ? team trump is filled with washington insiders @cnnpolitics\n",
            "Pred words: team trump is already filled with washington insiders\n",
            "Percent of unique sentences: 0.9090909090909091\n",
            "\n",
            "fbi docs claim clinton took furniture from state\n",
            "fbi docs claim clinton took furniture from state\n",
            "fbi docs claim clinton took furniture from state .\n",
            "fbi docs claim clinton took furniture from state\n",
            "fbi docs claim clinton took furniture from state\n",
            "fbi fbi docs claim clinton took furniture from state\n",
            "fbi fbi docs claim clinton took furniture from state\n",
            "fbi docs claim took furniture from state\n",
            "fbi claim clinton took furniture from state\n",
            "fbi docs claim clinton took furniture\n",
            "fbi docs claim clinton took furniture\n",
            "fbi from state\n",
            "Input words: fbi docs claim clinton took furniture from state\n",
            "Ref words: removing <unk> and furniture fbi documents claim clinton took items from state department\n",
            "Pred words: fbi docs claim clinton took furniture from state\n",
            "Percent of unique sentences: 0.5833333333333334\n",
            "\n",
            "7 things to watch for on election night\n",
            "7 things to watch for ' night\n",
            "7 things to watch for on election night\n",
            "7 things to watch for on government\n",
            "7 things to watch for ' election night\n",
            "7 things to watch for on night\n",
            "7 things to watch for on election night .\n",
            "7 things to watch for with times all\n",
            "7 things to watch for ' night ' .\n",
            "7 things to watch for ' night ' night\n",
            "Input words: 7 things to watch for on election night\n",
            "Ref words: 7 things to watch for on # election2016 night .\n",
            "Pred words: 7 things to watch for on election night\n",
            "Percent of unique sentences: 0.9\n",
            "\n",
            "how moscow uses interpol to pursue its enemies\n",
            "how moscow uses interpol to pursue its enemies\n",
            "how moscow uses interpol to pursue its first an enemies\n",
            "how moscow uses interpol to pursue its enemies\n",
            "moscow uses interpol to pursue its enemies\n",
            "how moscow uses interpol to pursue its enemies\n",
            "how moscow uses interpol to pursue its first an enemies\n",
            "how moscow uses interpol to pursue its enemies\n",
            "how moscow uses interpol to pursue its enemies\n",
            "how moscow uses interpol to pursue its enemies\n",
            "moscow uses interpol to pursue its enemies\n",
            "how moscow uses interpol to pursue its drug an enemies\n",
            "how moscow uses interpol to pursue enemies\n",
            "Input words: how moscow uses interpol to pursue its enemies\n",
            "Ref words: how russia uses interpol to pursue its crooks and its political enemies .\n",
            "Pred words: how moscow uses interpol to pursue its enemies\n",
            "Percent of unique sentences: 0.38461538461538464\n",
            "\n",
            "bans all samsung galaxy note7 phones from airplanes\n",
            "bans all samsung galaxy note7 phones from airplanes\n",
            "bans all samsung galaxy note7 phones from airplanes with times all\n",
            "bans all samsung galaxy note7 phones from airplanes\n",
            "bans all samsung galaxy note7 phones from airplanes .\n",
            "bans all samsung galaxy note7 phones from airplanes\n",
            "bans all samsung galaxy note7 phones from airplanes\n",
            "bans all samsung galaxy note7 phones from airplanes\n",
            "his samsung galaxy note7 phones from airplanes\n",
            "was samsung galaxy note7 phones from airplanes\n",
            "bans all samsung galaxy note7 phones\n",
            "bans all samsung galaxy note7 phones\n",
            "Input words: bans all samsung galaxy note7 phones from airplanes\n",
            "Ref words: @usdot has banned all samsung galaxy note7 phones from airplanes . samsung customers call 1844 - 365 - 6197 for info .\n",
            "Pred words: bans all samsung galaxy note7 phones from airplanes\n",
            "Percent of unique sentences: 0.5\n",
            "\n",
            "donald trump allies focus anger on another target\n",
            "donald trump allies focus anger on another target\n",
            "donald trump allies focus anger on another target on government\n",
            "donald trump allies focus anger on another target\n",
            "donald trump allies focus anger ' another target\n",
            "donald trump allies focus anger on another target .\n",
            "donald playing focus anger on another target\n",
            "donald in allies focus anger on another target\n",
            "donald trump allies focus anger \" another target\n",
            "donald trump allies focus anger on government\n",
            "in allies focus anger on another target\n",
            "donald trump allies focus anger on another target\n",
            "Input words: donald trump allies focus anger on another target\n",
            "Ref words: trump and allies focus anger on other republicans some of the <unk> voices on the right seem poised to .\n",
            "Pred words: donald trump allies focus anger on another target\n",
            "Percent of unique sentences: 0.75\n",
            "\n",
            "donald trump and family preview path to victory\n",
            "donald trump and family preview path to victory\n",
            "donald # trump and family preview path to victory\n",
            "donald trump and family preview path to victory\n",
            "donald trump and family preview path to victory\n",
            "donald trump and family preview path to victory\n",
            "donald playing family preview path to victory\n",
            "trump and family preview path to victory\n",
            "donald # trump and family preview path to victory\n",
            "donald in family preview path to victory\n",
            "in family preview path to victory\n",
            "donald playing family preview path to victory\n",
            "the and family preview path to victory\n",
            "Input words: donald trump and family preview path to victory\n",
            "Ref words: trump and family preview path to victory they sat down with george <unk> in d.c.\n",
            "Pred words: donald trump and family preview path to victory\n",
            "Percent of unique sentences: 0.5384615384615384\n",
            "\n",
            "you can now check on a facebook chatbot\n",
            "you can now check on a facebook chatbot with times all\n",
            "you can now check on a facebook chatbot via radio\n",
            "you can now check on a facebook chatbot .\n",
            "you can now check on a facebook chatbot via radio\n",
            "you can now check on a facebook chatbot\n",
            "the you can now check on a facebook chatbot\n",
            "you can now check on a facebook chatbot\n",
            "you can now check on a facebook chatbot via twitter\n",
            "you can now check on a facebook chatbot via twitter\n",
            "Input words: you can now check on a facebook chatbot\n",
            "Ref words: you can now check via a facebook chatbot\n",
            "Pred words: you can now check on a facebook chatbot\n",
            "Percent of unique sentences: 0.6\n",
            "\n",
            "gretchen carlson on her fight against sexual harassment\n",
            "gretchen on her fight against sexual harassment\n",
            "gretchen carlson a her fight against sexual harassment\n",
            "gretchen carlson ' her fight against sexual harassment\n",
            "her fight against sexual harassment\n",
            "gretchen carlson on her fight against sexual harassment\n",
            "gretchen carlson \" her fight against sexual harassment\n",
            "gretchen carlson on her fight against sexual harassment .\n",
            "gretchen carlson , her fight against sexual harassment\n",
            "fight against sexual harassment\n",
            "gretchen carlson at fight against sexual harassment\n",
            "Input words: gretchen carlson on her fight against sexual harassment\n",
            "Ref words: got ta read it ! my fight against sexual harassment\n",
            "Pred words: gretchen carlson on her fight against sexual harassment\n",
            "Percent of unique sentences: 0.9090909090909091\n",
            "\n",
            "alec baldwin <unk> ' <unk>\n",
            "trump says alec baldwin <unk> ' <unk>\n",
            "says alec baldwin <unk> ' <unk>\n",
            "trump says alec baldwin <unk> ' <unk>\n",
            "alec baldwin <unk> ' <unk>\n",
            "baldwin <unk> ' <unk>\n",
            "trump says alec baldwin <unk>\n",
            "alec baldwin ' <unk>\n",
            "alec baldwin <unk>\n",
            "<unk> ' <unk>\n",
            "Input words: trump says alec baldwin <unk> ' <unk>\n",
            "Ref words: we all know # snl is pro liberal democrat right ? so when donald trump says # <unk> <unk> ' <unk>\n",
            "Pred words: alec baldwin <unk> ' <unk>\n",
            "Percent of unique sentences: 0.8\n",
            "\n",
            "overdosing on vc lessons from 71 ipos\n",
            "overdosing on vc lessons from 71 ipos\n",
            "overdosing overdosing on vc lessons from 71 ipos\n",
            "overdosing vc lessons from 71 ipos\n",
            "vc lessons from 71 ipos\n",
            "overdosing on vc lessons from 71 ipos .\n",
            "overdosing \" vc lessons from 71 ipos\n",
            "overdosing news lessons from 71 ipos\n",
            "overdosing overdosing vc lessons from 71 ipos\n",
            "overdosing 71 ipos\n",
            "Input words: overdosing on vc lessons from 71 ipos\n",
            "Ref words: it 's possible to overdose on vc <unk> uses data from 71 ipos to help founders avoid this fate\n",
            "Pred words: overdosing on vc lessons from 71 ipos\n",
            "Percent of unique sentences: 0.9\n",
            "\n",
            "being american in the years\n",
            "in the donald trump years\n",
            "in the years\n",
            "his american in the years\n",
            "donald in the years\n",
            "the donald trump years\n",
            "in the years\n",
            "donald trump years\n",
            "the years\n",
            "trump years\n",
            "Input words: being american in the donald trump years\n",
            "Ref words: democracy requires the presumption of good faith in our fellow citizensbeing american in the trump years\n",
            "Pred words: being american in the years\n",
            "Percent of unique sentences: 0.9\n",
            "\n",
            "donald trump cancels \" hannity \" interview\n",
            "donald trump cancels \" hannity \" hannity \" interview\n",
            "donald trump cancels \" hannity \" interview .\n",
            "donald trump cancels \" hannity \" interview\n",
            "donald trump cancels \" hannity \" interview\n",
            "donald in cancels \" hannity \" interview\n",
            "donald trump cancels \" hannity \" hannity .\n",
            "donald trump cancels \" hannity \" hannity\n",
            "donald trump cancels \" hannity \" interview\n",
            "donald playing cancels \" hannity \" interview\n",
            "in cancels \" hannity \" interview\n",
            "the cancels \" hannity \" interview\n",
            "Input words: donald trump cancels \" hannity \" interview\n",
            "Ref words: cancels \" # hannity \" interview after more # sexualassault reports come ht\n",
            "Pred words: donald trump cancels \" hannity \" interview\n",
            "Percent of unique sentences: 0.75\n",
            "\n",
            "how to spend 36 hours in toronto\n",
            "how to spend 36 hours in toronto with times all\n",
            "how to spend 36 hours in toronto\n",
            "how to spend 36 hours in toronto on government\n",
            "how to spend 36 hours in toronto .\n",
            "how to spend 36 hours in toronto\n",
            "how to spend 36 hours in toronto\n",
            "how to spend 36 hours in toronto on government\n",
            "how to spend 36 hours in toronto\n",
            "hours in toronto\n",
            "in toronto\n",
            "Input words: how to spend 36 hours in toronto\n",
            "Ref words: great for a day stay at one of our toronto hotels ! 36 hours in\n",
            "Pred words: how to spend 36 hours in toronto\n",
            "Percent of unique sentences: 0.5454545454545454\n",
            "\n",
            "researchers accidentally turn carbon dioxide into ethanol\n",
            "researchers accidentally turn carbon dioxide into ethanol with times all\n",
            "researchers accidentally turn carbon dioxide into ethanol\n",
            "researchers accidentally turn carbon dioxide into ethanol .\n",
            "researchers accidentally turn carbon dioxide into ethanol\n",
            "turn carbon dioxide into ethanol\n",
            "researchers accidentally turn carbon dioxide into ethanol\n",
            "researchers accidentally turn carbon dioxide into ethanol\n",
            "researchers turn carbon dioxide into ethanol\n",
            "researchers dioxide into ethanol\n",
            "Input words: researchers accidentally turn carbon dioxide into ethanol\n",
            "Ref words: is the <unk> back in the bottle ? researchers at @ornl accidentally turn carbon dioxide into ethanol\n",
            "Pred words: researchers accidentally turn carbon dioxide into ethanol\n",
            "Percent of unique sentences: 0.6\n",
            "\n",
            "researchers accidentally turn carbon dioxide into ethanol\n",
            "researchers accidentally turn carbon dioxide into ethanol with times all\n",
            "researchers accidentally turn carbon dioxide into ethanol\n",
            "researchers accidentally turn carbon dioxide into ethanol .\n",
            "researchers accidentally turn carbon dioxide into ethanol\n",
            "turn carbon dioxide into ethanol\n",
            "researchers accidentally turn carbon dioxide into ethanol\n",
            "researchers accidentally turn carbon dioxide into ethanol\n",
            "researchers turn carbon dioxide into ethanol\n",
            "researchers dioxide into ethanol\n",
            "Input words: researchers accidentally turn carbon dioxide into ethanol\n",
            "Ref words: researchers turn carbon dioxide into ethanol . this will make every finn interested to fight the climate change !\n",
            "Pred words: researchers accidentally turn carbon dioxide into ethanol\n",
            "Percent of unique sentences: 0.6\n",
            "\n",
            "what donald trump taught us about ourselves\n",
            "what donald donald trump taught us about ourselves\n",
            "what donald trump taught us about ourselves\n",
            "what donald donald trump taught us about ourselves\n",
            "what donald in trump taught us about ourselves\n",
            "what donald donald trump taught us about ourselves .\n",
            "what donald trump taught us about ourselves .\n",
            "what donald donald donald trump taught us about ourselves\n",
            "what in trump taught us about ourselves\n",
            "what donald in trump taught us about ourselves\n",
            "what clinton trump taught us about ourselves\n",
            "what donald trump taught us about ourselves\n",
            "what donald trump taught us about ourselves\n",
            "Input words: what donald trump taught us about ourselves\n",
            "Ref words: what fish taco taught us about ourselves\n",
            "Pred words: what donald trump taught us about ourselves\n",
            "Percent of unique sentences: 0.6153846153846154\n",
            "\n",
            "researchers accidentally turn carbon dioxide into ethanol\n",
            "researchers accidentally turn carbon dioxide into ethanol with times all\n",
            "researchers accidentally turn carbon dioxide into ethanol\n",
            "researchers accidentally turn carbon dioxide into ethanol .\n",
            "researchers accidentally turn carbon dioxide into ethanol\n",
            "turn carbon dioxide into ethanol\n",
            "researchers accidentally turn carbon dioxide into ethanol\n",
            "researchers accidentally turn carbon dioxide into ethanol\n",
            "researchers turn carbon dioxide into ethanol\n",
            "researchers dioxide into ethanol\n",
            "Input words: researchers accidentally turn carbon dioxide into ethanol\n",
            "Ref words: <unk> researchers accidentally turned carbon dioxide into ethanol\n",
            "Pred words: researchers accidentally turn carbon dioxide into ethanol\n",
            "Percent of unique sentences: 0.6\n",
            "\n",
            "billy bush is officially out at nbc\n",
            "billy billy bush is officially out at nbc\n",
            "billy bush is officially is officially out at nbc\n",
            "billy bush is officially out at nbc with times all\n",
            "billy bush is officially out at nbc\n",
            "billy billy officially is officially out at nbc\n",
            "billy bush is officially is officially out at nbc\n",
            "billy bush is officially is officially out at nbc .\n",
            "billy bush is officially out at nbc\n",
            "billy billy bush is officially out at nbc\n",
            "Input words: billy bush is officially out at nbc\n",
            "Ref words: billy bush officially departs nbc so this guy gets fired and his partner in crime is running for p\n",
            "Pred words: billy bush is officially out at nbc\n",
            "Percent of unique sentences: 0.6\n",
            "\n",
            "watch the disney <unk> demo day here\n",
            "watch the disney <unk> demo day here .\n",
            "watch the disney <unk> demo day here\n",
            "disney <unk> demo day here\n",
            "the disney <unk> demo day here\n",
            "watch the <unk> demo day here\n",
            "watch disney <unk> demo day here\n",
            "<unk> demo day here\n",
            "disney <unk> demo day here .\n",
            "watch day here\n",
            "demo day here\n",
            "Input words: watch the disney <unk> demo day here\n",
            "Ref words: watch the disney <unk> demo day , right here\n",
            "Pred words: watch the disney <unk> demo day here\n",
            "Percent of unique sentences: 0.9090909090909091\n",
            "\n",
            "david letterman shop at target these days\n",
            "david letterman shop at target these days\n",
            "david letterman shop at target these days with times all\n",
            "david letterman david letterman shop at target these days\n",
            "david letterman shop at target these days\n",
            "david letterman shop at target these days\n",
            "david letterman david letterman shop at target these days\n",
            "david letterman shop at target these days\n",
            "david letterman to target these days\n",
            "david letterman at target these days\n",
            "david letterman 's target these days\n",
            "david letterman shop at these days\n",
            "Input words: david letterman shop at target these days\n",
            "Ref words: great profile of # modern # aging & amp ; next career / @letterman shop at target these days\n",
            "Pred words: david letterman shop at target these days\n",
            "Percent of unique sentences: 0.5833333333333334\n",
            "\n",
            "texas voters claim machines switching their votes\n",
            "texas voters claim machines switching their votes on government\n",
            "texas voters claim machines switching their votes\n",
            "voters claim machines switching their votes\n",
            "texas voters claim machines switching their votes .\n",
            "texas voters claim machines switching their votes\n",
            "texas voters claim machines switching their votes\n",
            "texas voters claim machines switching their votes\n",
            "claim machines switching their votes\n",
            "switching their votes\n",
            "texas says votes\n",
            "Input words: texas voters claim machines switching their votes\n",
            "Ref words: some texas residents are claiming machines have switched their # votes from donald j . trump to hillary clinton .\n",
            "Pred words: texas voters claim machines switching their votes\n",
            "Percent of unique sentences: 0.6363636363636364\n",
            "\n",
            "goodbye nintendo <unk> , hello ' switch\n",
            "goodbye nintendo <unk> , hello ' switch\n",
            "goodbye nintendo <unk> , hello ' switch ' switch\n",
            "goodbye nintendo <unk> , hello ' switch\n",
            "the goodbye nintendo <unk> , hello ' switch\n",
            "goodbye nintendo <unk> , hello ' switch\n",
            "nintendo <unk> , hello ' switch\n",
            "goodbye nintendo , hello ' switch\n",
            "goodbye , hello ' switch\n",
            "goodbye\n",
            "Input words: goodbye nintendo <unk> , hello ' switch\n",
            "Ref words: goodbye <unk> , hello switch . switch ' is <unk> next game console a <unk> mobile & amp ; home console\n",
            "Pred words: goodbye nintendo <unk> , hello ' switch\n",
            "Percent of unique sentences: 0.7\n",
            "\n",
            "the nyt review of googles pixel smartphone\n",
            "the nyt review of googles pixel smartphone\n",
            "the nyt review of googles pixel smartphone .\n",
            "the with times all nyt review of googles pixel smartphone\n",
            "nyt review of googles pixel smartphone\n",
            "the nyt review of googles pixel smartphone\n",
            "the nyt review of googles pixel smartphone\n",
            "trump nyt review of googles pixel smartphone\n",
            "the nyt review of googles pixel smartphone\n",
            "nyt review of googles pixel smartphone\n",
            "the nyt review of googles pixel smartphone\n",
            "googles pixel smartphone\n",
            "Input words: the nyt review of googles pixel smartphone\n",
            "Ref words: new york times google pixel review assessing the new smartphone\n",
            "Pred words: the nyt review of googles pixel smartphone\n",
            "Percent of unique sentences: 0.5\n",
            "\n",
            "has the republican feminist awakening begun ?\n",
            "has the republican feminist awakening begun ?\n",
            "the republican feminist awakening begun ?\n",
            "has the republican feminist awakening begun ?\n",
            "has the republican feminist awakening begun ?\n",
            "trump republican feminist awakening begun ?\n",
            "the republican feminist awakening begun ?\n",
            "has the republican feminist awakening begun ?\n",
            "trump republican feminist awakening begun ?\n",
            "the with times all begun ?\n",
            "with times all begun ?\n",
            "his begun ?\n",
            "Input words: has the republican feminist awakening begun ?\n",
            "Ref words: republican women having a feminist moment ?\n",
            "Pred words: has the republican feminist awakening begun ?\n",
            "Percent of unique sentences: 0.5\n",
            "\n",
            "canada military probes mysterious arctic pinging noise\n",
            "canada military probes mysterious arctic pinging noise\n",
            "canada military probes mysterious arctic pinging noise\n",
            "canada military probes mysterious arctic pinging noise\n",
            "canada military probes mysterious arctic pinging noise\n",
            "canada military probes mysterious arctic pinging noise\n",
            "canada military probes mysterious arctic pinging noise\n",
            "canada military probes mysterious arctic pinging noise .\n",
            "canada military probes mysterious arctic pinging noise\n",
            "canada military probes mysterious arctic pinging noise\n",
            "canada military probes mysterious arctic pinging noise\n",
            "canada military mysterious arctic pinging noise\n",
            "Input words: canada military probes mysterious arctic pinging noise\n",
            "Ref words: gt ; & gt ; bbc # uk canada probes arctic pinging the canadian military probes a mysterious arctic p .\n",
            "Pred words: canada military probes mysterious arctic pinging noise\n",
            "Percent of unique sentences: 0.25\n",
            "\n",
            "how donald trump reshaped the election map\n",
            "how donald in reshaped the election map\n",
            "how donald trump reshaped the election map\n",
            "how donald trump reshaped the election map\n",
            "how donald trump reshaped the map\n",
            "how donald trump reshaped the election map on map\n",
            "how in reshaped the election map\n",
            "how donald trump reshaped the election map ' map\n",
            "in for reshaped the election map\n",
            "donald trump reshaped the election map\n",
            "trump reshaped the election map\n",
            "the election map\n",
            "Input words: how donald trump reshaped the election map\n",
            "Ref words: how t reshaped the election map to the right\n",
            "Pred words: how donald trump reshaped the election map\n",
            "Percent of unique sentences: 0.8333333333333334\n",
            "\n",
            "broken promises of genetically modified crops\n",
            "broken broken promises of genetically modified crops\n",
            "broken promises of genetically modified crops on government\n",
            "broken promises of genetically modified crops\n",
            "broken promises of genetically modified crops\n",
            "broken promises of genetically modified crops .\n",
            "the broken promises of genetically modified crops\n",
            "broken broken promises of genetically modified crops\n",
            "promises of genetically modified crops\n",
            "broken promises day\n",
            "Input words: the broken promises of genetically modified crops\n",
            "Ref words: doubts about the promised bounty of genetically modified crops . ny times oct .\n",
            "Pred words: broken promises of genetically modified crops\n",
            "Percent of unique sentences: 0.7\n",
            "\n",
            "being american in the years\n",
            "in the donald trump years\n",
            "in the years\n",
            "his american in the years\n",
            "donald in the years\n",
            "the donald trump years\n",
            "in the years\n",
            "donald trump years\n",
            "the years\n",
            "trump years\n",
            "Input words: being american in the donald trump years\n",
            "Ref words: obama and hillary the two heroes of america being american in the trump years\n",
            "Pred words: being american in the years\n",
            "Percent of unique sentences: 0.9\n",
            "\n",
            "child refugees in turkey making uk clothes\n",
            "child refugees in turkey making uk clothes\n",
            "child refugees in turkey making uk clothes\n",
            "child refugees in turkey making uk clothes\n",
            "child refugees in turkey making uk clothes\n",
            "child refugees in turkey making uk clothes\n",
            "child refugees in turkey making uk clothes .\n",
            "child refugees in turkey to uk clothes\n",
            "child refugees in turkey making uk clothes\n",
            "child refugees in turkey making uk\n",
            "child refugees in turkey making uk\n",
            "child refugees in turkey making uk .\n",
            "Input words: child refugees in turkey making uk clothes\n",
            "Ref words: child refugees found working in clothes factory in turkey\n",
            "Pred words: child refugees in turkey making uk clothes\n",
            "Percent of unique sentences: 0.4166666666666667\n",
            "\n",
            "researchers accidentally turn carbon dioxide into ethanol\n",
            "researchers accidentally turn carbon dioxide into ethanol with times all\n",
            "researchers accidentally turn carbon dioxide into ethanol\n",
            "researchers accidentally turn carbon dioxide into ethanol .\n",
            "researchers accidentally turn carbon dioxide into ethanol\n",
            "turn carbon dioxide into ethanol\n",
            "researchers accidentally turn carbon dioxide into ethanol\n",
            "researchers accidentally turn carbon dioxide into ethanol\n",
            "researchers turn carbon dioxide into ethanol\n",
            "researchers dioxide into ethanol\n",
            "Input words: researchers accidentally turn carbon dioxide into ethanol\n",
            "Ref words: researchers at <unk> <unk> national <unk> accidentally turn carbon dioxide into ethanol\n",
            "Pred words: researchers accidentally turn carbon dioxide into ethanol\n",
            "Percent of unique sentences: 0.6\n",
            "\n",
            "confident \" over new fbi email probe\n",
            "confident \" over new fbi email probe\n",
            "the confident \" over new fbi email probe\n",
            "confident \" over new fbi email probe\n",
            "confident \" over new fbi email probe\n",
            "the confident \" over new fbi email probe\n",
            "confident \" over new fbi email probe\n",
            "\" over new fbi email probe\n",
            "confident \" over new fbi email probe\n",
            "confident \" the fbi email probe\n",
            "was fbi email probe\n",
            "Input words: confident \" over new fbi email probe\n",
            "Ref words: fbi probes new clinton emails linked to anthony weiner\n",
            "Pred words: confident \" over new fbi email probe\n",
            "Percent of unique sentences: 0.45454545454545453\n",
            "\n",
            "facebook finally starts showing ads in groups\n",
            "facebook finally starts showing ads in groups\n",
            "facebook finally starts showing ads in groups\n",
            "facebook finally starts showing ads in groups\n",
            "facebook finally to starts showing ads in groups\n",
            "facebook finally starts showing ads stop groups\n",
            "facebook finally starts showing ads in groups\n",
            "facebook finally starts showing ads in groups\n",
            "facebook finally starts showing ads in groups\n",
            "facebook finally starts showing ads in groups\n",
            "facebook finally starts showing ads in groups\n",
            "facebook finally starts showing ads in groups\n",
            "Input words: facebook finally starts showing ads in groups\n",
            "Ref words: where facebook is going to start posting ads\n",
            "Pred words: facebook finally starts showing ads in groups\n",
            "Percent of unique sentences: 0.25\n",
            "\n",
            "how does the electoral college work ?\n",
            "how does the electoral college work ?\n",
            "how does the electoral college work ?\n",
            "how does the electoral college work ? .\n",
            "how does the electoral college work ?\n",
            "how does the electoral college work ?\n",
            "how does electoral college work ?\n",
            "how does the electoral college work\n",
            "does the electoral college work ?\n",
            "the electoral college work ?\n",
            "trump electoral college work ?\n",
            "Input words: how does the electoral college work ?\n",
            "Ref words: every four years i have to remind myself how on earth the us electoral college works .\n",
            "Pred words: how does the electoral college work ?\n",
            "Percent of unique sentences: 0.6363636363636364\n",
            "\n",
            "broken promises of genetically modified crops\n",
            "broken broken promises of genetically modified crops\n",
            "broken promises of genetically modified crops on government\n",
            "broken promises of genetically modified crops\n",
            "broken promises of genetically modified crops\n",
            "broken promises of genetically modified crops .\n",
            "the broken promises of genetically modified crops\n",
            "broken broken promises of genetically modified crops\n",
            "promises of genetically modified crops\n",
            "broken promises day\n",
            "Input words: the broken promises of genetically modified crops\n",
            "Ref words: every picture tells the story broken promises of genetically modified crops\n",
            "Pred words: broken promises of genetically modified crops\n",
            "Percent of unique sentences: 0.7\n",
            "\n",
            "michelle obama denounces trumps words on women\n",
            "michelle obama denounces trumps words on government\n",
            "michelle obama denounces trumps words 's women\n",
            "michelle obama denounces trumps words\n",
            "michelle words on women\n",
            "michelle obama denounces trumps words ' women\n",
            "michelle obama denounces trumps words , women\n",
            "michelle obama denounces trumps words .\n",
            "michelle obama denounces trumps words a women\n",
            "michelle obama denounces trumps words\n",
            "michelle obama denounces trumps words to women\n",
            "michelle obama denounces trumps words\n",
            "michelle words on women\n",
            "michelle words ' women\n",
            "michelle words 's women\n",
            "Input words: michelle obama denounces trumps words on women\n",
            "Ref words: michelle obama denounces sexist video words on women\n",
            "Pred words: michelle obama denounces trumps words on women\n",
            "Percent of unique sentences: 0.8\n",
            "\n",
            "how donald trump reshaped the election map\n",
            "how donald in reshaped the election map\n",
            "how donald trump reshaped the election map\n",
            "how donald trump reshaped the election map\n",
            "how donald trump reshaped the map\n",
            "how donald trump reshaped the election map on map\n",
            "how in reshaped the election map\n",
            "how donald trump reshaped the election map ' map\n",
            "in for reshaped the election map\n",
            "donald trump reshaped the election map\n",
            "trump reshaped the election map\n",
            "the election map\n",
            "Input words: how donald trump reshaped the election map\n",
            "Ref words: this to me it what swayed it , <unk> mitt , how trump reshaped the election map\n",
            "Pred words: how donald trump reshaped the election map\n",
            "Percent of unique sentences: 0.8333333333333334\n",
            "\n",
            "freed students reunite with families in nigeria\n",
            "freed students reunite with families in nigeria .\n",
            "freed students reunite with families in nigeria\n",
            "freed students reunite with families in nigeria\n",
            "freed students , with families in nigeria\n",
            "freed students reunite with families in nigeria\n",
            "freed students reunite with families in nigeria\n",
            "freed students reunite with families in nigeria 's students\n",
            "students reunite with families in nigeria\n",
            "in nigeria\n",
            "Input words: freed students reunite with families in nigeria\n",
            "Ref words: 21 chibok girls freed from terrorists # <unk> & amp ; reunite with families in nigeria !\n",
            "Pred words: freed students reunite with families in nigeria\n",
            "Percent of unique sentences: 0.6\n",
            "\n",
            "Average BLEU score: 0.20991715644779207\n",
            "Average Unique sentences: 0.655\n"
          ]
        }
      ],
      "source": [
        "## refactoring the author's code\n",
        "import random \n",
        "from decode import BeamSearch\n",
        "\n",
        "# Set random seed\n",
        "random.seed(args.seed)\n",
        "torch.manual_seed(args.seed)\n",
        "torch.cuda.manual_seed_all(args.seed)\n",
        "\n",
        "# Decode sample using beam search\n",
        "beam_searcher = BeamSearch(model, txtfield, args)\n",
        "beam_searcher.decode_sample(test_iter, txtfield, args, num_samples=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_y20pddrd-z",
        "outputId": "06b115f8-2cbb-46e7-ef41-4b6fc4a84df5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i 'm so tired that i 'll sleep as soon as i go home\n",
            "i 'm so tired that i 'll sleep as soon as i go home .\n",
            "i 'm so tired that i 'll sleep as soon as i go home\n",
            "i for tired that i 'll sleep as soon as i go home\n",
            "i 'm so tired , i 'll sleep as soon as i go home\n",
            "i 'm so tired that i 'll sleep as soon as i go home\n",
            "i 'm so tired that i 'll sleep as soon as i go home via radio\n",
            "i 'm so tired that i 'll sleep as soon as i go home\n",
            "i 'm so tired that i 'll sleep as soon as i go\n",
            "i 'm so tired that i 'll sleep as soon as i go home\n",
            "i 'm so tired that i 'll sleep as soon\n",
            "Input words: i 'm so tired that i 'll sleep as soon as i go home\n",
            "Ref words: i 'm so tired and i 'll sleep when i get home\n",
            "Pred words: i 'm so tired that i 'll sleep as soon as i go home\n",
            "Percent of unique sentences: 0.6363636363636364\n",
            "\n",
            "Average BLEU score: 0.2737928561916526\n",
            "Average Unique sentences: 0.636\n"
          ]
        }
      ],
      "source": [
        "## own code\n",
        "new_src_text = \"I'm so tired that I'll sleep as soon as I go home\"\n",
        "new_ref_test = \"I'm so tired and I'll sleep when I get home\"\n",
        "pd.DataFrame([[new_src_text, new_ref_test]]).to_csv(f'{args.data_file}/sample.tsv',sep='\\t', header=None, index=None)\n",
        "\n",
        "sample_data = TabularDataset(os.path.join(args.data_file,'sample'+\".tsv\"), format=\"TSV\", fields=fields, skip_header=False)\n",
        "sample_iter = BucketIterator(sample_data, \n",
        "                            batch_size=args.batch_size, \n",
        "                            sort_key=lambda x: len(x.src),\n",
        "                            sort=True,\n",
        "                            shuffle=False,\n",
        "                            repeat=False)\n",
        "\n",
        "beam_searcher.decode_sample(sample_iter, txtfield, args, num_samples=1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
